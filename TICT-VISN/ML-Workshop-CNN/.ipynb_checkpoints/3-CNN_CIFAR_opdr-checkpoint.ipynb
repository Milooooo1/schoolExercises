{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "owuMk_guREX5",
    "outputId": "ba7cd846-f092-473b-e412-32461a6d779b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from scriptss.load_data import load_train, load_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN bouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_lLaBNewZk0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 31)\n"
     ]
    }
   ],
   "source": [
    "# Het importeren en bewerken van de data \n",
    "train_images, train_labels = load_train()\n",
    "test_images, test_labels = load_test()\n",
    "\n",
    "# Normalizeren van de images\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "print(train_images[0].shape)\n",
    "# Reshapen van de images zodat ze de juiste dimensies hebben\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFleZ8yEyFtk"
   },
   "outputs": [],
   "source": [
    "## Onze CNN\n",
    "\n",
    "\n",
    "\n",
    "# Stap 1: bepaal hoeveel filters je wilt, hoe groot je filter size moet zijn (let op je filter size \n",
    "# mag niet te groot zijn vergeleken met je images), en wat je pool size is. \n",
    "num_filters = 3\n",
    "filter_size = (28 * 31) #868\n",
    "pool_size = 100\n",
    "\n",
    "# Stap 2: maak het model.\n",
    "#    In de array die je aan sequential meegeeft, zet je alle layers die in het model moeten:\n",
    "#    Conv2D, parameters: num_filters, filter_size, input_shape=(x, y, z)\n",
    "#    MaxPooling2D, parameters: pool_size=pool_size\n",
    "#    Flatten,\n",
    "#    Dense, parameters: aantal outputs, activation='softmax'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', input_dim=train_images.shape[1]))\n",
    "model.add(Dense(128, activation='relu', input_dim=train_images.shape[1]))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "he8Zs-Sd2TID"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "1875/1875 [==============================] - 2s 771us/step - loss: 0.1037 - accuracy: 0.9674\n",
      "Epoch 2/9\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.0836 - accuracy: 0.9727\n",
      "Epoch 3/9\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0724 - accuracy: 0.9762\n",
      "Epoch 4/9\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.0641 - accuracy: 0.9789\n",
      "Epoch 5/9\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.0568 - accuracy: 0.9810\n",
      "Epoch 6/9\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.0503 - accuracy: 0.9832\n",
      "Epoch 7/9\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.0470 - accuracy: 0.9845\n",
      "Epoch 8/9\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0427 - accuracy: 0.9855\n",
      "Epoch 9/9\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.0425 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b60f6c8430>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stap 3: het compilen van het model. \n",
    "# model.compile parameters: 'adam', loss='categorial_crossentropy', metrics=['accuracy']\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Stap 4: fit het model. \n",
    "#    Data om op te trainen: train_images, to_categorial(train_labels)\n",
    "#    epochs = 3\n",
    "#    validation_data = test_images, to_categorial(test_labels)\n",
    "model.fit(train_images, train_labels, epochs=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 470us/step - loss: 1.8907 - accuracy: 0.6163\n",
      "0.6162999868392944\n"
     ]
    }
   ],
   "source": [
    "# Stap 5: evalueer het model\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)#, verbose=2)#to_categorical(test_labels), verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pS8vERMeHh8j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 4310\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stap 6: extra layer(s). Wat gebeurt er als je een extra Conv Layer toevoegd aan je model? \n",
    "#    Voeg een extra layer(s) toe en train het model opnieuw. \n",
    "# Stap 7: parameters. Wat gebeurt er bijvoorbeeld als je geen softmax gebruikt maar een andere activatie? \n",
    "#    Pas op z'n minst 1 parameter aan en train je model opnieuw. \n",
    "\n",
    "#(softmax ipv relu verminderd de accuracy van 90% naar 70%)\n",
    "#Een Dense (relu) layer minder maakt nauwelijks verschil\n",
    "\n",
    "predictions = model.predict([test_images])\n",
    "\n",
    "import random\n",
    "index = random.randint(0,len(test_images))\n",
    "print(\"index: \" + str(index))\n",
    "print(np.argmax(predictions[index]))\n",
    "plt.imshow(test_images[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "# Data inladen\n",
    "(train_images10, train_labels10), (test_images10, test_labels10) = cifar10.load_data()\n",
    "\n",
    "plt.imshow(train_images10[4])\n",
    "plt.show()\n",
    "\n",
    "# Normalizeren\n",
    "train_images10, test_images10 = train_images10 / 255.0, test_images10 / 255.0\n",
    "print(train_images10.shape)\n",
    "print(train_labels10[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-20f9cf32ec4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel_cif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    221\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                                 input_list)\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    860\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2682\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2683\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2684\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2685\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    235\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                          \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 10)"
     ]
    }
   ],
   "source": [
    "# Stap 8: bouw je eigen CNN voor de CIFAR-10 dataset. \n",
    "# Tip: gebruik meerdere Conv2D en MaxPooling layers\n",
    "# LET OP: gebruik 'softmax' alleen bij je laatste Dense layer. Gebruik 'relu' voor de andere Conv2D/Dense layers. \n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "n_classes = 10\n",
    "\n",
    "model_cif = Sequential([])\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_cif.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cif.fit(\n",
    "  train_images10,\n",
    "  to_categorical(train_labels10),\n",
    "  epochs= 15#hint: meer dan 3,\n",
    "  validation_data=(test_images10, to_categorical(test_labels10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_cif.evaluate(test_images10,  to_categorical(test_labels10), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronnen\n",
    "* https://victorzhou.com/blog/keras-cnn-tutorial/ Bezocht: 9/3/2020\n",
    "* https://www.tensorflow.org/tutorials/images/cnn Bezocht: 13/3/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
